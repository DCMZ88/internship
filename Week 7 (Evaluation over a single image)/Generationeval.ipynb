{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a00d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a08e3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures that there is enough memory allocation for the model to load\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb9e61cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.20it/s]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"image-text-to-text\",\n",
    "    model=\"google/gemma-3-4b-it\",\n",
    "    device=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2132b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input Image\n",
    "url = \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\"\n",
    "\n",
    "# File path to save the questions\n",
    "file_path = 'url.txt'\n",
    "\n",
    "# Writing the questions string to a txt file\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(url)  # Strip any leading/trailing whitespace\n",
    "\n",
    "print(f\"Questions have been saved to {file_path}\")\n",
    "\n",
    "\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db61180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of questions to be generated \n",
    "questions = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "150b9858",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Task : Generate a list of {questions} simple questions for each of the following three topics related to object detection for other Visual Language Models to infer:\n",
    "\n",
    "Instructions :\n",
    "1. **Classes of Object Detection**: Ask questions about the categories or types of objects detected in the image (e.g., \"What is the object class?\" or \"Which class is the object?\").\n",
    "2. **Number of Objects**: Ask questions related to how many objects are detected in an image (e.g., \"How many objects are in the image?\" or \"What is the count of objects?\").\n",
    "3. **Colour**: Ask questions regarding the colours of objects detected (e.g., \"What is the colour of the object?\" or \"Which colour is the object?\").\n",
    "\n",
    "Ensure that each question is clear, simple, and can be answered with short, concise answers.\n",
    "Ensure each question is not repeated.\n",
    "Only include the questions and category.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01f48c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Task:\n",
    "Generate a list of {questions} SIMPLE questions for the following topic related to object detection for other Visual Language Models that can be easily infered from the input image:\n",
    "\n",
    "Instructions:\n",
    "-  **Classes of Object Detection**: Ask questions for the categories or types of objects detected in the image (e.g., \"What is the object class?\" or \"Which class is the object?\").\n",
    "-  The answers to the questions should be specifically object/objects detected in the image \n",
    "-  Do not include colours of the objects in the questions\n",
    "Ensure that each question is clear, simple, and can be answered with short, concise answers.\n",
    "Ensure each question is not repeated.\n",
    "The output should only include the questions, Do not include the header.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94aaa335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task:\n",
      "Generate a list of 20 SIMPLE questions for the following topic related to object detection for other Visual Language Models that can be easily infered from the input image:\n",
      "\n",
      "Instructions:\n",
      "-  **Classes of Object Detection**: Ask questions for the categories or types of objects detected in the image (e.g., \"What is the object class?\" or \"Which class is the object?\").\n",
      "-  The answers to the questions should be specifically object/objects detected in the image \n",
      "-  Do not include colours of the objects in the questions\n",
      "Ensure that each question is clear, simple, and can be answered with short, concise answers.\n",
      "Ensure each question is not repeated.\n",
      "The output should only include the questions, Do not include the header.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee60caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eda477f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  What is the main animal in the image?\n",
      "2.  What type of clothing is the person wearing?\n",
      "3.  What is on the ground near the person?\n",
      "4.  What is the surface the person and dog are sitting on?\n",
      "5.  What is the body of water visible in the background?\n",
      "6.  What is the dog wearing?\n",
      "7.  What is the person holding?\n",
      "8.  What is the object near the dog's paw?\n",
      "9.  What is the primary element in the background?\n",
      "10. What is the general environment depicted?\n",
      "11. What is the person doing?\n",
      "12. What is the dog doing?\n",
      "13. What is the object between the person and the dog?\n",
      "14. What is the texture of the ground?\n",
      "15. What is the shape of the waves?\n",
      "16. What is the light source in the image?\n",
      "17. What is the main feature of the dog’s appearance?\n",
      "18. What is the person’s posture?\n",
      "19. What is the color of the dog’s fur?\n",
      "20. What is the main element in the foreground?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"url\": f\"{url}\"},\n",
    "            {\"type\": \"text\", \"text\": f\"{prompt}\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "output = pipe(text=messages, max_new_tokens=1000)\n",
    "print(output[0][\"generated_text\"][-1][\"content\"])\n",
    "output_text = output[0][\"generated_text\"][-1][\"content\"]\n",
    "# Okay, let's take a look! \n",
    "# Based on the image, the animal on the candy is a **turtle**. \n",
    "# You can see the shell shape and the head and legs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeb13d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions have been saved to questions(OD).txt\n"
     ]
    }
   ],
   "source": [
    "# File path to save the questions\n",
    "file_path = '/home/jovyan/Evaluation/questions(OD).txt'\n",
    "\n",
    "cleaned_questions = '\\n'.join([line.split('. ', 1)[1] for line in output_text.splitlines() if line])\n",
    "# Writing the questions string to a txt file\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(cleaned_questions)  # Strip any leading/trailing whitespace\n",
    "\n",
    "print(f\"Questions have been saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9fdbe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question-answer pairs have been saved to questions(OD).json .\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "qa_raw_list = output_text.strip().split(\"\\n\")\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "# Step 2: Loop through the raw list to extract the questions and answers\n",
    "for i in range(0, len(qa_raw_list), 3):  # Step by 3 since each question and answer is followed by a blank line\n",
    "    question = re.sub(r'^\\d+\\.\\s*', '', qa_raw_list[i]).strip()\n",
    "    questions.append(question)\n",
    "    answer = qa_raw_list[i + 1].strip().lstrip('* ')  # Clean the answer (remove '* ' prefix)\n",
    "    answers.append(answer)\n",
    "    \n",
    "qa_data = [{\"question\": question, \"answer\": answer} for question, answer in zip(questions, answers)]    \n",
    "\n",
    "file_name= 'questions(OD).json'\n",
    "# Step 4: Save the dictionary as a JSON file\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(qa_data, json_file, indent=4)\n",
    "\n",
    "print(f\"The question-answer pairs have been saved to {file_name} .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64c7b92a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Open and load the JSON file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestions_answers(Gemma3).json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Print the contents of the JSON file\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(data, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))  \u001b[38;5;66;03m# This will format the JSON for better readability\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open('questions_answers(Gemma3).json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print the contents of the JSON file\n",
    "print(json.dumps(data, indent=4,ensure_ascii=False))  # This will format the JSON for better readability\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
