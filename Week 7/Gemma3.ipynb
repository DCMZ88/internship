{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202bce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1a4798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures that there is enough memory allocation for the model to load\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "190e8e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"image-text-to-text\",\n",
    "    model=\"google/gemma-3-4b-it\",\n",
    "    device=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7e496a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "from PIL import Image\n",
    "import json\n",
    "import requests\n",
    "\n",
    "processor_answer = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "model_answer = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d8878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input Image\n",
    "url = \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c7f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of questions to be generated \n",
    "questions = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83dab06a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a young woman sitting on a sandy beach with her golden retriever dog. The woman is wearing a plaid shirt and black pants and is holding the dog's leash. The dog is sitting on the sand and is looking up at the woman with a smile on its face. The ocean can be seen in the background with waves crashing onto the shore. The sky is orange and pink, indicating that it is either sunrise or sunset. The overall mood of the image is peaceful and serene.\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your .txt file\n",
    "file_path = 'caption.txt'  # Replace with your file's path\n",
    "\n",
    "try:\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read the contents of the file\n",
    "        caption = file.read()\n",
    "        \n",
    "        # Print the contents of the file\n",
    "        print(caption)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file at {file_path} was not found.\")\n",
    "except IOError:\n",
    "    print(\"Error: An error occurred while reading the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f546379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input prompt \n",
    "prompt = f\"\"\"\n",
    "Task: Given the image input and the caption provided, generate {questions} simple, clear, and unique questions about the image. Each question should focus on one specific aspect of the scene and be easy to understand. The questions should be varied in type and explore different general aspects of the image, but each question should only contain one part.\n",
    "\n",
    "Caption:\n",
    "\"{caption}\"\n",
    "\n",
    "Instructions:\n",
    "- Generate {questions} distinct questions, each focusing on one unique detail or aspect of the scene.\n",
    "- Ensure each question is simple and contains only one part (e.g., \"What is the expression on the character's face?\" or \"What is the color of the sky?\").\n",
    "- Questions should explore different general aspects, such as:\n",
    "    - The appearance or actions of any characters (people, animals, etc.)\n",
    "    - The environment (natural elements like the sky, ocean, land, etc.)\n",
    "    - Emotions or mood conveyed by the scene\n",
    "    - Time of day or lighting (e.g., sunrise, sunset, bright, dark, etc.)\n",
    "    - The relationship between characters (if applicable)\n",
    "    - Objects or features in the scene (e.g., clothing, accessories, weather conditions)\n",
    "- Avoid compound questions or combining more than one query in a single question.\n",
    "- Each question should explore a different aspect of the scene in a clear and simple manner.\n",
    "- The output should only include the questions and nothing else.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a4f757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task: Given the image input and the caption provided, generate 19 simple, clear, and unique questions about the image. Each question should focus on one specific aspect of the scene and be easy to understand. The questions should be varied in type and explore different general aspects of the image, but each question should only contain one part.\n",
      "\n",
      "Caption:\n",
      "\"The image shows a young woman sitting on a sandy beach with her golden retriever dog. The woman is wearing a plaid shirt and black pants and is holding the dog's leash. The dog is sitting on the sand and is looking up at the woman with a smile on its face. The ocean can be seen in the background with waves crashing onto the shore. The sky is orange and pink, indicating that it is either sunrise or sunset. The overall mood of the image is peaceful and serene.\"\n",
      "\n",
      "Instructions:\n",
      "- Generate 19 distinct questions, each focusing on one unique detail or aspect of the scene.\n",
      "- Ensure each question is simple and contains only one part (e.g., \"What is the expression on the character's face?\" or \"What is the color of the sky?\").\n",
      "- Questions should explore different general aspects, such as:\n",
      "    - The appearance or actions of any characters (people, animals, etc.)\n",
      "    - The environment (natural elements like the sky, ocean, land, etc.)\n",
      "    - Emotions or mood conveyed by the scene\n",
      "    - Time of day or lighting (e.g., sunrise, sunset, bright, dark, etc.)\n",
      "    - The relationship between characters (if applicable)\n",
      "    - Objects or features in the scene (e.g., clothing, accessories, weather conditions)\n",
      "- Avoid compound questions or combining more than one query in a single question.\n",
      "- Each question should explore a different aspect of the scene in a clear and simple manner.\n",
      "- The output should only include the questions and nothing else.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c033f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d498f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  What color is the dog’s fur?\n",
      "2.  What is the woman wearing?\n",
      "3.  What is the dog doing?\n",
      "4.  What type of surface is the woman sitting on?\n",
      "5.  What is the color of the ocean?\n",
      "6.  What is visible in the background?\n",
      "7.  What color is the sky?\n",
      "8.  What is the woman holding?\n",
      "9.  What is the dog looking at?\n",
      "10. What is the woman’s facial expression?\n",
      "11. Is the scene taking place during the day or night?\n",
      "12. What kind of weather is it?\n",
      "13. What is the texture of the sand?\n",
      "14. What is the dog’s posture?\n",
      "15. What is the leash pattern like?\n",
      "16. What is the woman doing with her hand?\n",
      "17. What is the overall mood of the image?\n",
      "18. Are there any waves visible?\n",
      "19. What is the lighting like in the image?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"url\": f\"{url}\"},\n",
    "            {\"type\": \"text\", \"text\": f\"{prompt}\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "output = pipe(text=messages, max_new_tokens=1000)\n",
    "print(output[0][\"generated_text\"][-1][\"content\"])\n",
    "output_text = output[0][\"generated_text\"][-1][\"content\"]\n",
    "# Okay, let's take a look! \n",
    "# Based on the image, the animal on the candy is a **turtle**. \n",
    "# You can see the shell shape and the head and legs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86ec2ce8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' What color is the dog’s fur?', ' What is the woman wearing?', ' What is the dog doing?', ' What type of surface is the woman sitting on?', ' What is the color of the ocean?', ' What is visible in the background?', ' What color is the sky?', ' What is the woman holding?', ' What is the dog looking at?', 'What is the woman’s facial expression?', 'Is the scene taking place during the day or night?', 'What kind of weather is it?', 'What is the texture of the sand?', 'What is the dog’s posture?', 'What is the leash pattern like?', 'What is the woman doing with her hand?', 'What is the overall mood of the image?', 'Are there any waves visible?', 'What is the lighting like in the image?']\n"
     ]
    }
   ],
   "source": [
    "# Given string (from the list you provided)\n",
    "questions_string = output_text\n",
    "\n",
    "# Replace the escaped \\\\n with actual newline characters\n",
    "questions_string = questions_string.replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "# Split the string into individual questions by newline characters\n",
    "questions = questions_string.split(\"\\n\")\n",
    "\n",
    "# Optional: Remove the numbering and \"1.\", \"2.\" part of each question\n",
    "cleaned_questions = [q.split(\". \", 1)[1] for q in questions if q]\n",
    "\n",
    "# Print the result\n",
    "print(cleaned_questions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6ce9e60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions have been saved to 'questions.txt'\n"
     ]
    }
   ],
   "source": [
    "# Open a file in write mode\n",
    "with open('questions.txt', 'w') as file:\n",
    "    # Iterate through the list of questions\n",
    "    for question in cleaned_questions:\n",
    "        # Write each question on a new line\n",
    "        file.write(question + '\\n')\n",
    "\n",
    "print(\"Questions have been saved to 'questions.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09399dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What color is the dog’s fur?', ' What is the woman wearing?', ' What is the dog doing?', ' What type of surface is the woman sitting on?', ' What is the color of the ocean?', ' What is visible in the background?', ' What color is the sky?', ' What is the woman holding?', ' What is the dog looking at?', 'What is the woman’s facial expression?', 'Is the scene taking place during the day or night?', 'What kind of weather is it?', 'What is the texture of the sand?', 'What is the dog’s posture?', 'What is the leash pattern like?', 'What is the woman doing with her hand?', 'What is the overall mood of the image?', 'Are there any waves visible?', 'What is the lighting like in the image?']\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your .txt file\n",
    "file_path = 'questions.txt'  # Replace with your file's path\n",
    "\n",
    "try:\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read the contents of the file\n",
    "        question = file.read()\n",
    "        cleaned_questions = question.strip().split('\\n')\n",
    "        print(cleaned_questions)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file at {file_path} was not found.\")\n",
    "except IOError:\n",
    "    print(\"Error: An error occurred while reading the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28c5b8eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tan', 'plaid shirt', 'sitting', 'sand', 'blue', 'ocean', 'white', 'dog', 'woman', 'smiling', 'day', 'sunny', 'soft', 'sitting', 'plaid', 'petting dog', 'happy', 'yes', 'sunny']\n"
     ]
    }
   ],
   "source": [
    "answers = [] \n",
    "for question in cleaned_questions:\n",
    "    inputs = processor_answer(image, question , return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    out = model_answer.generate(**inputs)\n",
    "    output = processor_answer.decode(out[0], skip_special_tokens=True)\n",
    "    answers.append(output)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee0503d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions and answers have been written to 'questions_answers(Qwen+Blip).json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Pair the questions with answers\n",
    "qa_data = [{\"question\": question, \"answer\": answer} for question, answer in zip(cleaned_questions, answers)]\n",
    "\n",
    "# Write the generated data to a JSON file\n",
    "with open(\"questions_answers(Qwen+Blip).json\", \"w\") as file:\n",
    "    json.dump(qa_data, file, indent=4)\n",
    "\n",
    "print(\"Questions and answers have been written to 'questions_answers(Qwen+Blip).json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1329cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"question\": \"What color is the dog’s fur?\",\n",
      "        \"answer\": \"tan\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \" What is the woman wearing?\",\n",
      "        \"answer\": \"plaid shirt\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \" What is the dog doing?\",\n",
      "        \"answer\": \"sitting\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \" What type of surface is the woman sitting on?\",\n",
      "        \"answer\": \"sand\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \" What is the color of the ocean?\",\n",
      "        \"answer\": \"blue\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \" What is visible in the background?\",\n",
      "        \"answer\": \"ocean\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \" What color is the sky?\",\n",
      "        \"answer\": \"white\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \" What is the woman holding?\",\n",
      "        \"answer\": \"dog\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \" What is the dog looking at?\",\n",
      "        \"answer\": \"woman\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the woman’s facial expression?\",\n",
      "        \"answer\": \"smiling\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"Is the scene taking place during the day or night?\",\n",
      "        \"answer\": \"day\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What kind of weather is it?\",\n",
      "        \"answer\": \"sunny\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the texture of the sand?\",\n",
      "        \"answer\": \"soft\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the dog’s posture?\",\n",
      "        \"answer\": \"sitting\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the leash pattern like?\",\n",
      "        \"answer\": \"plaid\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the woman doing with her hand?\",\n",
      "        \"answer\": \"petting dog\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the overall mood of the image?\",\n",
      "        \"answer\": \"happy\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"Are there any waves visible?\",\n",
      "        \"answer\": \"yes\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the lighting like in the image?\",\n",
      "        \"answer\": \"sunny\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open('questions_answers(Qwen+Blip).json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print the contents of the JSON file\n",
    "print(json.dumps(data, indent=4,ensure_ascii=False))  # This will format the JSON for better readability\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
