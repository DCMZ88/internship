# Data Curation 

## Methodology

- This week, we aim to evaluate a model's performance from their output of a text.
- Before that, Google recently released their new VLM Gemma 3, hence we will test the performance of their model\
  specifically their [Gemma-3-4B-it](https://huggingface.co/google/gemma-3-4b-it)
### Question Generation 
- The questions generated by the Google Gemma3 model are much more verbose and diverse compared to the other models so far.
- Questions generated are not repetitive when prompted to generate more than 20 questions which other models seemed to have struggled so far.
Note: Another consideration could be that this model contains 4B parameters whereas some other models used such as Qwen2 contained 2B parameters.

**Questions generated by Gemma-3**
```
1.  What color is the dog’s fur?
2.  What is the woman wearing?
3.  What is the dog doing?
4.  What type of surface is the woman sitting on?
5.  What is the color of the ocean?
6.  What is visible in the background?
7.  What color is the sky?
8.  What is the woman holding?
9.  What is the dog looking at?
10. What is the woman’s facial expression?
11. Is the scene taking place during the day or night?
12. What kind of weather is it?
13. What is the texture of the sand?
14. What is the dog’s posture?
15. What is the leash pattern like?
16. What is the woman doing with her hand?
17. What is the overall mood of the image?
18. Are there any waves visible?
19. What is the lighting like in the image?
```
# Data Analysis 

Now, we attempt to evaluate the performance of the different VLMs
 
