{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fcf3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4dcb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures that there is enough memory allocation for the model to load\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d6545f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.22it/s]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"image-text-to-text\",\n",
    "    model=\"google/gemma-3-4b-it\",\n",
    "    device=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a832fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "from PIL import Image\n",
    "import json\n",
    "import requests\n",
    "\n",
    "processor_answer = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "model_answer = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af310d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input Image\n",
    "url = \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3be5748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of questions to be generated \n",
    "questions = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b20216c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a young woman sitting on a sandy beach with her golden retriever dog. The woman is wearing a plaid shirt and black pants and is holding the dog's leash. The dog is sitting on the sand and is looking up at the woman with a smile on its face. The ocean can be seen in the background with waves crashing onto the shore. The sky is orange and pink, indicating that it is either sunrise or sunset. The overall mood of the image is peaceful and serene.\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your .txt file\n",
    "file_path = 'caption.txt'  # Replace with your file's path\n",
    "\n",
    "try:\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read the contents of the file\n",
    "        caption = file.read()\n",
    "        \n",
    "        # Print the contents of the file\n",
    "        print(caption)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file at {file_path} was not found.\")\n",
    "except IOError:\n",
    "    print(\"Error: An error occurred while reading the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1cfb198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input prompt \n",
    "prompt = f\"\"\"\n",
    "Task: Given the image input and the caption provided, generate {questions} simple, clear, and unique questions about the image. Each question should focus on one specific aspect of the scene and be easy to understand. The questions should be varied in type and explore different general aspects of the image, but each question should only contain one part.\n",
    "\n",
    "Caption:\n",
    "\"{caption}\"\n",
    "\n",
    "Instructions:\n",
    "- Generate {questions} distinct questions, each focusing on one unique detail or aspect of the scene.\n",
    "- Ensure each question is simple and contains only one part (e.g., \"What is the expression on the character's face?\" or \"What is the color of the sky?\").\n",
    "- Questions should explore different general aspects, such as:\n",
    "    - The appearance or actions of any characters (people, animals, etc.)\n",
    "    - The environment (natural elements like the sky, ocean, land, etc.)\n",
    "    - Emotions or mood conveyed by the scene\n",
    "    - Time of day or lighting (e.g., sunrise, sunset, bright, dark, etc.)\n",
    "    - The relationship between characters (if applicable)\n",
    "    - Objects or features in the scene (e.g., clothing, accessories, weather conditions)\n",
    "- Avoid compound questions or combining more than one query in a single question.\n",
    "- Each question should explore a different aspect of the scene in a clear and simple manner.\n",
    "- The output should only include the questions and nothing else.\n",
    "\n",
    "2. Provide a short and simple answer to the questions generated.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e28f94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task: Given the image input and the caption provided, generate 20 simple, clear, and unique questions about the image. Each question should focus on one specific aspect of the scene and be easy to understand. The questions should be varied in type and explore different general aspects of the image, but each question should only contain one part.\n",
      "\n",
      "Caption:\n",
      "\"The image shows a young woman sitting on a sandy beach with her golden retriever dog. The woman is wearing a plaid shirt and black pants and is holding the dog's leash. The dog is sitting on the sand and is looking up at the woman with a smile on its face. The ocean can be seen in the background with waves crashing onto the shore. The sky is orange and pink, indicating that it is either sunrise or sunset. The overall mood of the image is peaceful and serene.\"\n",
      "\n",
      "Instructions:\n",
      "- Generate 20 distinct questions, each focusing on one unique detail or aspect of the scene.\n",
      "- Ensure each question is simple and contains only one part (e.g., \"What is the expression on the character's face?\" or \"What is the color of the sky?\").\n",
      "- Questions should explore different general aspects, such as:\n",
      "    - The appearance or actions of any characters (people, animals, etc.)\n",
      "    - The environment (natural elements like the sky, ocean, land, etc.)\n",
      "    - Emotions or mood conveyed by the scene\n",
      "    - Time of day or lighting (e.g., sunrise, sunset, bright, dark, etc.)\n",
      "    - The relationship between characters (if applicable)\n",
      "    - Objects or features in the scene (e.g., clothing, accessories, weather conditions)\n",
      "- Avoid compound questions or combining more than one query in a single question.\n",
      "- Each question should explore a different aspect of the scene in a clear and simple manner.\n",
      "- The output should only include the questions and nothing else.\n",
      "\n",
      "2. Provide a short and simple answer to the questions generated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c99013c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d67477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  What color is the dog’s fur?\n",
      "    *   Yellow\n",
      "\n",
      "2.  What is the woman wearing?\n",
      "    *   A plaid shirt\n",
      "\n",
      "3.  What is the dog doing?\n",
      "    *   Sitting\n",
      "\n",
      "4.  What is the surface the woman is sitting on?\n",
      "    *   Sand\n",
      "\n",
      "5.  What is visible in the background?\n",
      "    *   The ocean\n",
      "\n",
      "6.  What color is the sky?\n",
      "    *   Orange and pink\n",
      "\n",
      "7.  What is the woman holding?\n",
      "    *   The dog’s leash\n",
      "\n",
      "8.  What is the dog looking at?\n",
      "    *   The woman\n",
      "\n",
      "9.  What is the dog’s facial expression?\n",
      "    *   A smile\n",
      "\n",
      "10. What type of weather is suggested by the waves?\n",
      "    *   A calm sea\n",
      "\n",
      "11. What is the woman doing with her hand?\n",
      "    *   Holding it out\n",
      "\n",
      "12. What is the texture of the sand?\n",
      "    *   Grainy\n",
      "\n",
      "13. What time of day is it likely?\n",
      "    *   Sunrise or sunset\n",
      "\n",
      "14. What is the woman’s clothing style?\n",
      "    *   Casual\n",
      "\n",
      "15. What is the dog’s breed?\n",
      "    *   Golden Retriever\n",
      "\n",
      "16. What is the color of the dog’s collar?\n",
      "    *   Multi-colored\n",
      "\n",
      "17. What is the woman’s posture?\n",
      "    *   Sitting\n",
      "\n",
      "18. What is the general mood of the image?\n",
      "    *   Peaceful and serene\n",
      "\n",
      "19. What is the woman’s hair color?\n",
      "    *   Dark\n",
      "\n",
      "20. What is the dog’s tail doing?\n",
      "    *   Upright\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"url\": f\"{url}\"},\n",
    "            {\"type\": \"text\", \"text\": f\"{prompt}\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "output = pipe(text=messages, max_new_tokens=1000)\n",
    "print(output[0][\"generated_text\"][-1][\"content\"])\n",
    "output_text = output[0][\"generated_text\"][-1][\"content\"]\n",
    "# Okay, let's take a look! \n",
    "# Based on the image, the animal on the candy is a **turtle**. \n",
    "# You can see the shell shape and the head and legs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65474bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question-answer pairs have been saved to 'questions_answers(Gemma3).json'.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "qa_raw_list = output_text.strip().split(\"\\n\")\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "# Step 2: Loop through the raw list to extract the questions and answers\n",
    "for i in range(0, len(qa_raw_list), 3):  # Step by 3 since each question and answer is followed by a blank line\n",
    "    question = re.sub(r'^\\d+\\.\\s*', '', qa_raw_list[i]).strip()\n",
    "    questions.append(question)\n",
    "    answer = qa_raw_list[i + 1].strip().lstrip('* ')  # Clean the answer (remove '* ' prefix)\n",
    "    answers.append(answer)\n",
    "    \n",
    "qa_data = [{\"question\": question, \"answer\": answer} for question, answer in zip(questions, answers)]    \n",
    "\n",
    "\n",
    "# Step 4: Save the dictionary as a JSON file\n",
    "with open('questions_answers(Gemma3).json', 'w') as json_file:\n",
    "    json.dump(qa_data, json_file, indent=4)\n",
    "\n",
    "print(\"The question-answer pairs have been saved to 'questions_answers(Gemma3).json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3697ac8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"question\": \"What color is the dog’s fur?\",\n",
      "        \"answer\": \"Yellow\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the woman wearing?\",\n",
      "        \"answer\": \"A plaid shirt\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the dog doing?\",\n",
      "        \"answer\": \"Sitting\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the surface the woman is sitting on?\",\n",
      "        \"answer\": \"Sand\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is visible in the background?\",\n",
      "        \"answer\": \"The ocean\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What color is the sky?\",\n",
      "        \"answer\": \"Orange and pink\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the woman holding?\",\n",
      "        \"answer\": \"The dog’s leash\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the dog looking at?\",\n",
      "        \"answer\": \"The woman\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the dog’s facial expression?\",\n",
      "        \"answer\": \"A smile\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What type of weather is suggested by the waves?\",\n",
      "        \"answer\": \"A calm sea\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the woman doing with her hand?\",\n",
      "        \"answer\": \"Holding it out\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the texture of the sand?\",\n",
      "        \"answer\": \"Grainy\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What time of day is it likely?\",\n",
      "        \"answer\": \"Sunrise or sunset\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the woman’s clothing style?\",\n",
      "        \"answer\": \"Casual\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the dog’s breed?\",\n",
      "        \"answer\": \"Golden Retriever\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the color of the dog’s collar?\",\n",
      "        \"answer\": \"Multi-colored\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the woman’s posture?\",\n",
      "        \"answer\": \"Sitting\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the general mood of the image?\",\n",
      "        \"answer\": \"Peaceful and serene\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the woman’s hair color?\",\n",
      "        \"answer\": \"Dark\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the dog’s tail doing?\",\n",
      "        \"answer\": \"Upright\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open('questions_answers(Gemma3).json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print the contents of the JSON file\n",
    "print(json.dumps(data, indent=4,ensure_ascii=False))  # This will format the JSON for better readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0706a6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
