{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b764dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures that there is enough memory allocation for the model to load\n",
    "import os\n",
    "import torch\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71095598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:16<00:16, 16.29s/it]"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# default: Load the model on the available device(s)\n",
    "model_QWEN = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-3B-Instruct\", torch_dtype=\"auto\", attn_implementation='eager', device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "# model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "#     \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "# default processor\n",
    "processor_QWEN = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e8590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_labels(labels_list, file,):\n",
    "    # Saves the labels in a json format \n",
    "    data ={\n",
    "        'Labels' : labels_list\n",
    "    }\n",
    "    \n",
    "    new_path = '/home/jovyan/Evaluation/Data'\n",
    "    \n",
    "    if not os.path.exists(new_path):\n",
    "        os.makedirs(new_path) # Create the directory if it doesn't exist\n",
    "        print(f\"{new_path} successfully created\")\n",
    "    \n",
    "    json_filename = file\n",
    "    json_filename = f'{json_filename}.json'\n",
    "    # Creates the new json file.\n",
    "    file_name = os.path.join(new_path , json_filename)\n",
    "    with open(file_name , 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=4)\n",
    "    print(f\"File : {json_filename} successfully created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f975627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the directory (library)\n",
    "directory_path = \"/home/jovyan/images\"\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory_path)\n",
    "\n",
    "# Filter out directories and show only files\n",
    "files = [file for file in files if os.path.isfile(os.path.join(directory_path, file))]\n",
    "\n",
    "# Print the list of files\n",
    "for index, file in enumerate(files):\n",
    "    # Optimize memory usage \n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    print(f\"Processing image {file}\")\n",
    "    \n",
    "    image_path = os.path.join(directory_path, file)\n",
    "\n",
    "    # Prompt for the Google's Gemma \n",
    "    prompt = f\"\"\"\n",
    "    Detect 10 simple objects in the image and list them out, do not repeat listed objects\n",
    "    Only Include the name of the objects.\n",
    "\n",
    "    Do not include the header.\n",
    "    The output should be in this format: \"dog , woman, ball\"\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": f\"{image_path}\",\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": f\"{prompt}\"},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Preparation for inference\n",
    "    text = processor_QWEN.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor_QWEN(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "\n",
    "    # Inference: Generation of the output\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model_QWEN.generate(**inputs, max_new_tokens=150)\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        output_text = processor_QWEN.batch_decode(\n",
    "            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "    # Converts all the text into lower caps.\n",
    "    output_text = output_text[0].lower()\n",
    "    labels_list = output_text.strip().split(', ')\n",
    "    print(labels_list)\n",
    "    save_labels(labels_list,file)\n",
    "    print(f\"Successfully processed Image {file} ,{index+1}/{len(files)} Images Processed\")\n",
    "    \n",
    "print(f\"All {len(files)} have been processed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
